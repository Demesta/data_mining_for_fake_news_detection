{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import sklearn\n",
    "import yake\n",
    "import spacy\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.0.6-cp38-cp38-macosx_10_9_x86_64.whl (12.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.5 MB 557 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n",
      "  Downloading spacy_legacy-3.0.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.3\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Downloading thinc-8.0.3-cp38-cp38-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from spacy) (4.61.0)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.1-cp38-cp38-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.4-cp38-cp38-macosx_10_9_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-macosx_10_9_x86_64.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from spacy) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from spacy) (46.1.3)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from spacy) (2.23.0)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.5.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting click<7.2.0,>=7.1.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=f68d66d3e2ce8d0f04de74cfe70217618e7cffe9268ee56e71a86fd9aeedfaa8\n",
      "  Stored in directory: /Users/andronikos/Library/Caches/pip/wheels/11/73/9a/f91ac1f1816436b16423617c5be5db048697ff152a9c4346f2\n",
      "Successfully built smart-open\n",
      "Installing collected packages: spacy-legacy, catalogue, murmurhash, blis, pydantic, cymem, srsly, wasabi, preshed, thinc, packaging, click, typer, smart-open, pathy, spacy\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.1\n",
      "    Uninstalling click-8.0.1:\n",
      "      Successfully uninstalled click-8.0.1\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.4 click-7.1.2 cymem-2.0.5 murmurhash-1.0.5 packaging-20.9 pathy-0.5.2 preshed-3.0.5 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2 wasabi-0.8.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LocationTrue = r'./True.csv'\n",
    "LocationFake = r'./Fake.csv'\n",
    "\n",
    "dfTrue = pd.read_csv(LocationTrue)\n",
    "dfFake = pd.read_csv(LocationFake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>'Fully committed' NATO backs new U.S. approach...</td>\n",
       "      <td>BRUSSELS (Reuters) - NATO allies on Tuesday we...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21413</th>\n",
       "      <td>LexisNexis withdrew two products from Chinese ...</td>\n",
       "      <td>LONDON (Reuters) - LexisNexis, a provider of l...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>Minsk cultural hub becomes haven from authorities</td>\n",
       "      <td>MINSK (Reuters) - In the shadow of disused Sov...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21415</th>\n",
       "      <td>Vatican upbeat on possibility of Pope Francis ...</td>\n",
       "      <td>MOSCOW (Reuters) - Vatican Secretary of State ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>Indonesia to buy $1.14 billion worth of Russia...</td>\n",
       "      <td>JAKARTA (Reuters) - Indonesia will buy 11 Sukh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>August 22, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21417 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "21412  'Fully committed' NATO backs new U.S. approach...   \n",
       "21413  LexisNexis withdrew two products from Chinese ...   \n",
       "21414  Minsk cultural hub becomes haven from authorities   \n",
       "21415  Vatican upbeat on possibility of Pope Francis ...   \n",
       "21416  Indonesia to buy $1.14 billion worth of Russia...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "21412  BRUSSELS (Reuters) - NATO allies on Tuesday we...     worldnews   \n",
       "21413  LONDON (Reuters) - LexisNexis, a provider of l...     worldnews   \n",
       "21414  MINSK (Reuters) - In the shadow of disused Sov...     worldnews   \n",
       "21415  MOSCOW (Reuters) - Vatican Secretary of State ...     worldnews   \n",
       "21416  JAKARTA (Reuters) - Indonesia will buy 11 Sukh...     worldnews   \n",
       "\n",
       "                     date  \n",
       "0      December 31, 2017   \n",
       "1      December 29, 2017   \n",
       "2      December 31, 2017   \n",
       "3      December 30, 2017   \n",
       "4      December 29, 2017   \n",
       "...                   ...  \n",
       "21412    August 22, 2017   \n",
       "21413    August 22, 2017   \n",
       "21414    August 22, 2017   \n",
       "21415    August 22, 2017   \n",
       "21416    August 22, 2017   \n",
       "\n",
       "[21417 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(dataframe):\n",
    "    symbols = \"[!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}'~\\n]\"\n",
    "    \n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "#     dataframe['title'] = dataframe['title'].str.replace(symbols, '', regex=True)\n",
    "    dataframe['text'] = dataframe['text'].str.lower()\n",
    "#     dataframe['text'] = dataframe['text'].str.replace(symbols, '', regex=True)\n",
    "\n",
    "preprocessing(dfTrue)\n",
    "preprocessing(dfFake)\n",
    "dfTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = dfTrue['title'].tolist()\n",
    "texts = dfTrue['text'].tolist()\n",
    "\n",
    "dictList = [dict() for x in range(len(titles))]\n",
    "\n",
    "\n",
    "# tf_idf = {}\n",
    "# for i in range(N):\n",
    "#     tokens = processed_text[i]\n",
    "#     counter = Counter(tokens + processed_title[i])\n",
    "#     for token in np.unique(tokens):\n",
    "#         tf = counter[token]/words_count\n",
    "#         df = doc_freq(token)\n",
    "#         idf = np.log(N/(df+1))\n",
    "#         tf_idf[doc, token] = tf*idf\n",
    "\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Republicans flip', 0.026233073037508336)\n",
      "('fight looms', 0.04940384002065631)\n",
      "('budget', 0.15831692877998726)\n"
     ]
    }
   ],
   "source": [
    "kw_extractor = yake.KeywordExtractor()\n",
    "# text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "text = titles[0]\n",
    "language = \"en\"\n",
    "max_ngram_size = 2\n",
    "deduplication_threshold = 0.1\n",
    "numOfKeywords = 20\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "keywords = custom_kw_extractor.extract_keywords(text)\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-10cca1744ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# text = \"\"\"spaCy is an open-source software library for advanced natural language processing,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# written in the programming languages Python and Cython. The library is published under the MIT license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# text = \"\"\"spaCy is an open-source software library for advanced natural language processing, \n",
    "# written in the programming languages Python and Cython. The library is published under the MIT license\n",
    "# and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "doc = nlp(text)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['budget fight', 'fight looms', 'fiscal script', 'flip fiscal', 'looms republicans', 'republicans flip']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_gram_range = (2, 2)\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([text])\n",
    "candidates = count.get_feature_names()\n",
    "print(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- https://lena-voita.github.io/nlp_course/word_embeddings.html\n",
    "https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/Keyword%20Extraction%20with%20TF-IDF%20and%20SKlearn.ipynb\n",
    "https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf -->\n",
    "\n",
    "https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
